# Architecture Deep Dive

## ğŸ“ System Architecture

### Overview

This system implements a **microservices-based, event-driven architecture** using Netflix Conductor for orchestration and Apache Kafka for asynchronous communication. The architecture follows modern cloud-native patterns for scalability, resilience, and maintainability.

---

## ğŸ¯ Core Design Principles

### 1. Event-Driven Communication

**Traditional Approach (Synchronous)**:
```
Service A â†’ HTTP Request â†’ Service B â†’ HTTP Response â†’ Service A
```
- Tight coupling
- Service A blocks waiting for Service B
- Cascading failures
- Limited scalability

**Our Approach (Asynchronous Event-Driven)**:
```
Service A â†’ Kafka Event â†’ Service B (processes async)
             â†“
Conductor â† Kafka Event â† Service B (publishes completion)
```
- Loose coupling
- Non-blocking operations
- Independent scaling
- Fault isolation

### 2. Sink-Based Event Pattern

**Problem**: How does Conductor know when an async task completes?

**Traditional Solution (Polling)**:
```
Conductor publishes event â†’ Wait Task polls Kafka â†’ Finds result â†’ Continues
```
- Inefficient (continuous polling)
- Higher latency
- Resource intensive

**Our Solution (Sink-Based)**:
```
Conductor publishes event with sink address â†’
Microservice processes â†’
Microservice publishes to sink â†’
Event Router completes EVENT task â†’
Conductor continues immediately
```
- Efficient (event-driven)
- Lower latency
- Resource efficient

### 3. Separation of Concerns

Each component has a single, well-defined responsibility:

| Component | Responsibility |
|-----------|---------------|
| **React App** | Visual workflow design & user interaction |
| **Ingestion Service** | Workflow deployment & data ingestion |
| **Conductor** | Workflow orchestration & state management |
| **Event Router** | Route completion events to Conductor |
| **Microservices** | Domain-specific processing |
| **DAG Monitor** | Airflow integration & monitoring |
| **Kafka** | Event streaming & message delivery |

### 4. Scalability by Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Horizontal Scaling                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Kafka Topics (Partitioned)                                 â”‚
â”‚    â”œâ”€ Partition 0 â†’ Consumer Instance 1                     â”‚
â”‚    â”œâ”€ Partition 1 â†’ Consumer Instance 2                     â”‚
â”‚    â””â”€ Partition N â†’ Consumer Instance N                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- Each microservice can be scaled independently
- Kafka partitions enable parallel processing
- No shared state between service instances

---

## ğŸ”„ Data Flow Patterns

### Pattern 1: Simple Async Task

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conductor   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1. Publish event
       â”‚    (KAFKA_PUBLISH task)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kafka Topic       â”‚
â”‚  (request topic)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 2. Consume event
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Microservice      â”‚
â”‚  - Process data    â”‚
â”‚  - Store result    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 3. Publish completion
       â”‚    (to conductor-events)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kafka Topic       â”‚
â”‚  (conductor-events)â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 4. Route event
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Event Router      â”‚
â”‚  - Find EVENT task â”‚
â”‚  - Complete task   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 5. Task completion
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conductor API     â”‚
â”‚  POST /tasks       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 6. Continue workflow
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Next Task         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pattern 2: Airflow Integration (Complex)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conductor   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1. Publish Airflow trigger request
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kafka Topic       â”‚
â”‚  (airflow-trigger) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 2. Consume trigger event
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Airflow Adapter   â”‚
â”‚  - Trigger DAG     â”‚
â”‚  - Get dag_run_id  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 3. Publish monitoring event
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kafka Topic       â”‚
â”‚  (dag-monitor)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 4. Consume monitoring event
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DAG Monitor       â”‚
â”‚  - Poll Airflow    â”‚
â”‚  - Wait for done   â”‚
â”‚  - Download files  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 5. Publish completion
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Event Router      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 6. Complete EVENT task
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conductor         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why This Pattern?**
- Airflow DAGs are long-running (minutes to hours)
- Polling is done by dedicated worker (not blocking Conductor)
- Separates concerns: trigger vs. monitor
- Enables parallel monitoring of multiple DAGs

### Pattern 3: Parallel Processing (Fork/Join)

```
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   Conductor      â”‚
                  â”‚   (FORK_JOIN)    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                             â”‚
            â–¼                             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Branch 1     â”‚            â”‚  Branch 2     â”‚
    â”‚  Email        â”‚            â”‚  Phone        â”‚
    â”‚  Validation   â”‚            â”‚  Validation   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                             â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ (JOIN)
                           â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  Continue      â”‚
                  â”‚  Workflow      â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefits**:
- Parallel execution reduces total time
- Independent failure handling per branch
- Conductor manages synchronization (JOIN)

---

## ğŸ§© Component Interactions

### 1. Workflow Deployment Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     User Action                                â”‚
â”‚  React App â†’ Design Workflow â†’ Click "Deploy"                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ HTTP POST /workflow/deploy
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Ingestion Service                               â”‚
â”‚                                                                 â”‚
â”‚  1. Extract XML configs from workflow tasks                    â”‚
â”‚  2. Convert XML â†’ JSON using dpservices.bin                    â”‚
â”‚  3. Upload JSON to S3                                          â”‚
â”‚  4. Download input file from MinIO â†’ Upload to S3              â”‚
â”‚  5. Update workflow tasks with S3 URIs                         â”‚
â”‚  6. Deploy workflow to Conductor (POST /api/metadata/workflow) â”‚
â”‚  7. Trigger workflow execution (POST /api/workflow/{name})     â”‚
â”‚  8. Return workflow_instance_id to React app                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Conductor Execution                             â”‚
â”‚                                                                 â”‚
â”‚  1. Start workflow                                             â”‚
â”‚  2. Execute first task (usually KAFKA_PUBLISH)                 â”‚
â”‚  3. Wait for EVENT task completion                             â”‚
â”‚  4. Continue to next task                                      â”‚
â”‚  5. Repeat until workflow completes                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Event Routing Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Microservice Completes Processing                 â”‚
â”‚                                                                 â”‚
â”‚  microservice.publish_completion_event():                      â”‚
â”‚    - workflowId: "abc-123"                                     â”‚
â”‚    - taskId: "email_hygiene_task"                              â”‚
â”‚    - eventType: "email_hygiene_completed"                      â”‚
â”‚    - data: { status: "success", ... }                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ Publish to Kafka
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Kafka: conductor-events                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ Consume
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Event Router                                â”‚
â”‚                                                                 â”‚
â”‚  1. extract_event_type(event)                                  â”‚
â”‚     â†’ "email_hygiene_completed"                                â”‚
â”‚                                                                 â”‚
â”‚  2. find_matching_event_task(workflowId, eventType)            â”‚
â”‚     â†’ GET /api/workflow/{workflowId}?includeTasks=true         â”‚
â”‚     â†’ Filter tasks where:                                      â”‚
â”‚        - taskType == "EVENT"                                   â”‚
â”‚        - status == "IN_PROGRESS"                               â”‚
â”‚        - sink matches eventType                                â”‚
â”‚     â†’ Found: task_id="xyz-789"                                 â”‚
â”‚                                                                 â”‚
â”‚  3. complete_event_task(workflowId, taskId, outputData)        â”‚
â”‚     â†’ POST /api/tasks                                          â”‚
â”‚        {                                                       â”‚
â”‚          "workflowInstanceId": "abc-123",                      â”‚
â”‚          "taskId": "xyz-789",                                  â”‚
â”‚          "status": "COMPLETED",                                â”‚
â”‚          "outputData": { ... }                                 â”‚
â”‚        }                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Conductor Continues Workflow                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Matching Logic**:
```python
# Event Router: find_matching_event_task()

# Step 1: Try exact task ID match (if provided in event)
if task_id_from_event:
    matching_task = find_task_by_id(tasks, task_id_from_event)
    if matching_task and matching_task.taskType == "EVENT":
        return matching_task

# Step 2: Try sink-based matching
for task in in_progress_event_tasks:
    task_sink = task.get('sink')  # e.g., "conductor:email_hygiene_completed"
    sink_event_type = normalize_sink(task_sink)  # â†’ "email_hygiene_completed"
    
    if sink_event_type.lower() == event_type.lower():
        return task  # Exact match

# Step 3: Fallback to reference name mapping
task_ref_name = EVENT_TO_TASK_MAPPING.get(event_type)
if task_ref_name:
    matching_task = find_task_by_ref_name(tasks, task_ref_name)
    return matching_task

# Step 4: No match found
return None
```

### 3. Retry Mechanism Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Workflow Execution Fails                       â”‚
â”‚  (Task status: FAILED)                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ Event published to conductor-events
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Ingestion Service (Kafka Consumer)                â”‚
â”‚                                                                 â”‚
â”‚  1. Detect status == "failed" in event                         â”‚
â”‚  2. process_retry_full(workflowId, event):                     â”‚
â”‚     a. GET /api/workflow/{workflowId}                          â”‚
â”‚     b. Find first failed task index                            â”‚
â”‚     c. Determine restart index:                                â”‚
â”‚        - If failed task is EVENT â†’ restart from previous       â”‚
â”‚        - Otherwise â†’ restart from failed task                  â”‚
â”‚     d. Build reset_tasks list (all tasks from restart point)   â”‚
â”‚     e. Create retry payload:                                   â”‚
â”‚        {                                                       â”‚
â”‚          "workflowId": "abc-123",                              â”‚
â”‚          "reRunFromTaskRefName": "trigger_email_hygiene",      â”‚
â”‚          "resetTasks": ["trigger_email_hygiene",               â”‚
â”‚                         "wait_for_email_hygiene"]              â”‚
â”‚        }                                                       â”‚
â”‚     f. Push retry payload to UI via WebSocket                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    React App (WebSocket)                        â”‚
â”‚                                                                 â”‚
â”‚  1. Receive retry payload                                      â”‚
â”‚  2. Display retry button to user                               â”‚
â”‚  3. User clicks "Retry"                                        â”‚
â”‚  4. POST /retry-workflow (to Ingestion Service)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Ingestion Service (Retry Endpoint)                    â”‚
â”‚                                                                 â”‚
â”‚  POST /retry-workflow:                                         â”‚
â”‚    1. Extract rerun_url from payload                           â”‚
â”‚    2. Forward retry request to Conductor:                      â”‚
â”‚       POST {rerun_url} with payload                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Conductor (Rerun API)                              â”‚
â”‚                                                                 â”‚
â”‚  POST /api/workflow/{workflowId}/rerun:                        â”‚
â”‚    1. Reset specified tasks to SCHEDULED                       â”‚
â”‚    2. Re-execute from reRunFromTaskRefName                     â”‚
â”‚    3. Preserve workflow context and previous outputs           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why This Design?**
- **Automatic Detection**: System detects failures without user monitoring
- **Smart Restart**: Identifies correct restart point (handles EVENT dependencies)
- **User Control**: User confirms retry (prevents unwanted retries)
- **Preserves State**: Workflow context maintained across retries

---

## ğŸ“¦ Storage Architecture

### Hybrid S3/MinIO Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Data Flow                               â”‚
â”‚                                                                 â”‚
â”‚  1. User uploads to MinIO (local testing)                      â”‚
â”‚     â””â”€ minio://raw-data/input.in                               â”‚
â”‚                                                                 â”‚
â”‚  2. Ingestion Service downloads from MinIO                     â”‚
â”‚     â””â”€ Local temp file                                         â”‚
â”‚                                                                 â”‚
â”‚  3. Ingestion Service uploads to S3 (production)               â”‚
â”‚     â””â”€ s3://bucket/conductor-poc/runs/{workflowId}/input.in    â”‚
â”‚                                                                 â”‚
â”‚  4. Airflow DAG processes in S3                                â”‚
â”‚     â””â”€ Output: s3://bucket/conductor-poc/runs/{wfId}/output.outâ”‚
â”‚                                                                 â”‚
â”‚  5. DAG Monitor downloads from S3                              â”‚
â”‚     â””â”€ Local temp file                                         â”‚
â”‚                                                                 â”‚
â”‚  6. DAG Monitor uploads to MinIO (for UI access)               â”‚
â”‚     â””â”€ minio://output-bucket/output.out                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why Hybrid?**
- **S3**: Production-ready, durable, accessible to Airflow
- **MinIO**: Local development, fast access, no AWS costs
- **Best of Both**: S3 for processing, MinIO for quick access

### File Naming Convention

```
S3 Structure:
s3://{bucket}/conductor-poc/
  â”œâ”€â”€ runs/
  â”‚   â””â”€â”€ {workflowId}/
  â”‚       â”œâ”€â”€ input.in                    # Input data
  â”‚       â”œâ”€â”€ output.out                  # Processed output
  â”‚       â”œâ”€â”€ report/
  â”‚       â”‚   â””â”€â”€ counts.txt              # Statistics
  â”‚       â”œâ”€â”€ NameParse_Stats.jsonl       # Service stats
  â”‚       â””â”€â”€ Email_Hygiene_Stats.jsonl   # Service stats
  â”œâ”€â”€ dp_name_parse.json                  # Service config
  â””â”€â”€ dp_email_hygiene.json               # Service config

MinIO Structure:
minio://
  â”œâ”€â”€ raw-data/
  â”‚   â””â”€â”€ input.in                        # Input files
  â”œâ”€â”€ name-parse-output/
  â”‚   â”œâ”€â”€ nameparse.out                   # Output files
  â”‚   â””â”€â”€ NameParse_Stats.jsonl           # Stats
  â””â”€â”€ email-hygiene-output/
      â”œâ”€â”€ email_hygiene.out
      â””â”€â”€ Email_Hygiene_Stats.jsonl
```

---

## ğŸ” Security Considerations

### 1. Service Communication

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Internal Network (Docker Bridge)                   â”‚
â”‚                                                                 â”‚
â”‚  - All services communicate within private network             â”‚
â”‚  - No external exposure except designated ports                â”‚
â”‚  - Services reference by hostname (e.g., kafka:9092)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Exposed Ports

| Port | Service | Purpose | Public? |
|------|---------|---------|---------|
| 8080 | Conductor | API & UI | Yes (localhost only) |
| 8000 | Ingestion Service | Deployment API | Yes (localhost only) |
| 9000 | MinIO | S3 API | Yes (localhost only) |
| 9001 | MinIO | Web Console | Yes (localhost only) |
| 5173 | React App | Workflow Designer | Yes (localhost only) |
| 9092 | Kafka | Message Broker | No (internal) |
| 2181 | Zookeeper | Kafka Coordination | No (internal) |

### 3. Credentials Management

```yaml
# Production Recommendations:
AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}           # From environment
AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}   # From environment
AWS_SESSION_TOKEN: ${AWS_SESSION_TOKEN}           # From environment
MWAA_SESSION_TOKEN: ${MWAA_SESSION_TOKEN}         # From environment

# Avoid hardcoding in docker-compose.yaml
# Use .env file (not committed to git)
# Or AWS Secrets Manager / Parameter Store
```

---

## ğŸš€ Scalability Patterns

### 1. Horizontal Scaling (Microservices)

```yaml
# Scale a service to 3 instances
docker-compose up -d --scale email-validator=3

# Kafka automatically distributes load across instances
# via consumer groups
```

**How It Works**:
- Each instance joins the same consumer group
- Kafka assigns partitions to consumers
- Load balanced automatically

### 2. Kafka Partitioning

```
Topic: email-validation-requests (3 partitions)

Partition 0 â†’ Consumer Instance 1
Partition 1 â†’ Consumer Instance 2
Partition 2 â†’ Consumer Instance 3

# Messages distributed by key:
kafka_request.key = "validation-${workflow.workflowId}"
# Same workflow always goes to same partition (ordering guaranteed)
```

### 3. Thread-Based Scaling (DAG Monitor)

```python
# dag_monitor_worker/service.py

executor = ThreadPoolExecutor(max_workers=10)

for message in consumer:
    event = message.value
    executor.submit(self.process_event, event)
    # Non-blocking: monitors up to 10 DAGs concurrently
```

**When to Use**:
- I/O-bound tasks (polling Airflow API)
- Long-running operations
- Independent processing units

---

## ğŸ›¡ï¸ Fault Tolerance

### 1. Retry Mechanisms

**Airflow Adapter**:
```python
max_retries = 3
backoff_seconds = 2

for attempt in range(1, max_retries + 1):
    try:
        result = trigger_dag_run(...)
        if successful:
            return result
    except Exception as e:
        if attempt < max_retries:
            time.sleep(backoff_seconds)
            backoff_seconds *= 2  # Exponential backoff
        else:
            publish_failure_event(...)
```

**Benefits**:
- Handles transient failures (network issues, rate limits)
- Exponential backoff prevents overwhelming services
- Eventual failure notification

### 2. Health Checks

```yaml
# docker-compose.yaml

conductor-server:
  healthcheck:
    test: ["CMD", "wget", "--quiet", "--spider", "http://localhost:8080/health"]
    interval: 30s
    timeout: 10s
    retries: 5
    start_period: 60s
```

**Benefits**:
- Services wait for dependencies before starting
- Automatic restart on failure
- Visibility into service health

### 3. Kafka Consumer Groups

```python
consumer = KafkaConsumer(
    'conductor-events',
    group_id='event-router-group',  # Consumer group
    enable_auto_commit=True,
    auto_commit_interval_ms=1000
)
```

**Benefits**:
- Offset tracking (resume from last processed message)
- No duplicate processing after restart
- Fault tolerance via consumer group rebalancing

---

## ğŸ“Š Monitoring & Observability

### 1. Logs

Each service logs to stdout (captured by Docker):
```python
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
```

**View Logs**:
```bash
docker-compose logs -f event-router
docker-compose logs -f --tail=100 airflow-adapter
```

### 2. Conductor UI

http://localhost:8080
- Workflow executions
- Task status and outputs
- Timeline view
- Error details

### 3. WebSocket Updates

React app receives real-time updates:
```javascript
const ws = new WebSocket('ws://localhost:8000/ws');
ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  // Display stats, errors, completion status
};
```

### 4. Kafka Monitoring

```bash
# Message count per topic
docker-compose exec kafka kafka-run-class kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 \
  --topic conductor-events

# Consumer lag
docker-compose exec kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe --group event-router-group
```

---

## ğŸ“ Best Practices

### 1. Event Design

**Good Event Structure**:
```json
{
  "workflowId": "abc-123",           # Required: identifies workflow
  "taskId": "email_validation_task", # Required: identifies task
  "eventType": "email_hygiene_completed", # Required: for routing
  "data": {
    "status": "success",             # Required: success/failure
    "result": "success",             # For backwards compatibility
    "stats_url": "minio://...",      # Optional: additional data
    "output_uri": "s3://...",
    "timestamp": "2026-01-11T12:00:00Z"
  }
}
```

### 2. Task Naming

**Consistent Naming Convention**:
```
{service}_{action}_{stage}

Examples:
- dp_email_hygiene              # Service task
- wait_for_email_hygiene        # Wait task
- trigger_airflow_dag           # Trigger task
- email_hygiene_completed       # Event type
```

### 3. Error Handling

**Always Publish Completion Events**:
```python
try:
    result = process_data(...)
    publish_completion_event(status="success", data=result)
except Exception as e:
    logger.error(f"Error: {e}")
    publish_completion_event(
        status="failed",
        error_message=str(e)
    )
```

### 4. Idempotency

**Handle Duplicate Events**:
```python
# Use workflow_id + task_id as unique key
processed_events = set()

def process_event(event):
    key = f"{event['workflowId']}:{event['taskId']}"
    if key in processed_events:
        logger.info(f"Skipping duplicate event: {key}")
        return
    processed_events.add(key)
    # Process event...
```

---

## ğŸ”® Future Enhancements

### 1. Service Mesh (Istio/Linkerd)

- **Benefits**: Traffic management, observability, security
- **Implementation**: Add sidecar proxies to each service

### 2. Distributed Tracing (Jaeger/Zipkin)

- **Benefits**: End-to-end request tracing across services
- **Implementation**: Add trace IDs to events, instrument code

### 3. Schema Registry (Confluent Schema Registry)

- **Benefits**: Enforce event schema contracts, versioning
- **Implementation**: Define Avro/Protobuf schemas for events

### 4. Event Sourcing

- **Benefits**: Full audit trail, replay capability
- **Implementation**: Store all events in append-only log

### 5. CQRS (Command Query Responsibility Segregation)

- **Benefits**: Separate read/write models, optimized queries
- **Implementation**: Dedicated read models from event stream

---

## ğŸ“š References

- [Netflix Conductor Documentation](https://conductor-oss.github.io/conductor/)
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Event-Driven Architecture Patterns](https://www.enterpriseintegrationpatterns.com/)
- [Microservices Patterns by Chris Richardson](https://microservices.io/patterns/)

---

**This architecture enables building scalable, resilient, event-driven data pipelines with minimal coupling and maximum flexibility.**
